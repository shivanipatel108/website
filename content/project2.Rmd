---
date: "2020-05-14"
output:
  pdf_document: default
  html_document: default
---
```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```

###Project 2

###Shivani Patel sjp2742


### 0:

  The dataset I chose for this project contains information relating to prostate cancer diagnostics and treatments for 134 separate patients. The numeric variables include pgtime, age, g2, grade, and gleason. The pgtime variable shows time to progression of cancer or last follow up in years, the age variable shows the patients' ages in years, the g2 variable shows the percentage of cancer cells in the G2 phase of the cell cycle as found by flow cytometry, the grade variable shows the grade of the tumor in the Farrow system, and the gleason variable shows the grade of the tumor in the Gleason system. There is one categorical variable, ploidy, which indicates the ploidy status of the tumor (diploid, tetraploid, or aneuploid). Lastly, there are two binary variables, pgstat and eet. The pgstat variable shows whether progression was observed or censored, and the eet variable shows if there was early endocrine therapy or not.

### 1:
```{R}
library(tidyverse)
library(ggplot2)
library(dplyr)

prostate <-read.csv("prostate.csv")
data("prostate")
glimpse(prostate)

manova1<-manova(cbind(grade, gleason, g2)~ploidy, data=prostate)
summary(manova1)

prostate%>%group_by(ploidy)%>%summarize(mean(grade),mean(gleason), mean(g2))

summary.aov(manova1)

pairwise.t.test(prostate$grade, prostate$ploidy, p.adj="none")
pairwise.t.test(prostate$gleason, prostate$ploidy, p.adj="none")
pairwise.t.test(prostate$g2, prostate$ploidy, p.adj="none")

1-.95^13
0.05/13

```

  I first conducted a MANOVA test, which was significant with a p-value of less than 0.05. This showed that significant differences were found among the 3 types of ploidys for at least one of the numeric dependent variables of grade, gleason, and g2. Pillai trace was around 0.493, pseudo F(6, 260) was 14.177, and p was less than 0.0001.

  I then ran univariate ANOVAs for each numeric dependent variable, which showed that all of the numeric variables were significant as well, with p values less than 0.05. For grade, F(2, 131) was around 5.375 and p was less than 0.05, for gleason, F(2, 131) was around 4.794 and p was less than 0.05, and for g2, F(2, 131) was 53.437 and p was less than 0.05.

  I then performed post hoc t-tests, which showed that prior to adjusting the significance level, aneuploid/diploid and diploid/tetraploid significantly differed from one another in terms of grade, diploid/tetraploid significantly differed from one another in terms of gleason, and aneuploid/tetraploid and diploid/tetraploid significantly differed from one another in terms of g2.

  After adjusting with the boneferroni adjusted significance level of 0.0038, I found that neither of the ploidys significantly differed from one another in terms of grade, diploid/tetraploid still significantly differed from one another in terms of gleason, and aneuploid/tetraploid and diploid/tetraploid still significantly differed from one another in terms of g2. I performed 13 tests in total, including 1 MANOVA, 3 ANOVAs, and 9 t tests. The probability of getting at least one type-I error if unadjusted was around 48.67%. 

  The MANOVA and ANOVA random samples/independent observations assumption was probably met, as this dataset was random and seemed to have relatively independent observations. The MANOVA multivariate normality was likely met as each group had n=25+, but the ANOVA normal distribution assumption was likely not met, as I suspect not all groups had a normal distribution. The MANOVA homogeneity assumption was likely not met as there probably wasn't equal covariance between any 2 DVs, and the ANOVA equal variance assumption was also likely not met within each of my groups. The MANOVA linear relationships assumptions was likely not met among all of my variables, the no extreme outliers assumption was also likely not met as I spotted a few outliers in my data, and the no multicollinearity assumption was also likey violated as I suspect some of my DVs were pretty correlated.

### 2:
```{R}
rand <- data.frame(prostate$eet, prostate$age)
glimpse(rand)

rand%>%group_by(prostate.eet)%>%
  summarize(means=mean(prostate.age))%>%summarize(`mean_diff:`=diff(means))

rand_dist<-vector()
for(i in 1:5000){
new<-data.frame(pros.age=sample(rand$prostate.age),pros.eet=rand$prostate.eet)
rand_dist[i]<-mean(new[new$pros.eet==2,]$pros.age)-
mean(new[new$pros.eet==1,]$pros.age)}

{hist(rand_dist,main="",ylab=""); abline(v = 0.642,col="red")}

mean(rand_dist>0.642)*2

```

  I performed a randomization test on my two variables, age and eet. The null hypothesis was that mean age is the same for people both having early endocrine therapy (eet), and not having it. The alternative hypothesis was that mean age is different for people having eet and not having eet. I found that the true mean difference between the two means was around 0.642. I then computed a p-value on the randomization distribution, which corresponds to the probability of observing a mean difference as extreme as the original data mean difference. I obtained a p-value of 0.586. Since this number is not less than 0.05, the null hypothesis was accepted, meaning that mean age is the same for people both having eet and not having eet. In the plot to visualize the null distribution and the test statistic, I found that my test statistic layed slightly to the right of the middle of the null distribution, but only by a small amount.

### 3:
```{R}
prostate$gleason_c <- prostate$gleason - mean(prostate$gleason)
fitproject2<-lm(g2 ~ gleason_c*pgstat, data=prostate)
summary(fitproject2)


ggplot(prostate, aes(x = gleason_c, y = g2)) +
    geom_point(aes(color=pgstat)) + geom_smooth(method="lm")


#normality assumption
residsproj2<-lm(g2 ~ gleason_c*pgstat, data=prostate)$residuals
ggplot()+geom_histogram(aes(residsproj2),bins=10)

#homoskedsaticity assumption
fitvalsproj2<-lm(g2 ~ gleason_c*pgstat, data=prostate)$fitted.values
ggplot()+geom_point(aes(fitvalsproj2,residsproj2))+geom_hline(yintercept=0, color='red')

#linearity assumption
ggplot()+geom_qq(aes(sample=residsproj2))+geom_qq_line(aes(sample=residsproj2))


##install.packages("lmtest")
##install.packages("sandwich")
library(lmtest)
library(sandwich)

coeftest(fitproject2, vcov=vcovHC(fitproject2))

set.seed(348)
bogusproj2<-data.frame(y=prostate$g2,replicate(5,rnorm(134)))
head(bogusproj2,3)
summary(lm(y~.,data=bogusproj2))

```

  I ran a linear regression model with interaction predicting g2 from gleason and pgstat, and mean-centered the numeric variable gleason. The intercept of around 15.00 showed that when both gleason_c is average and pgstat is 0 (no progression observed), g2 is 15. The gleason_c coefficient estimate of around 2.88 showed that when pgstat is 0, g2 is 2.88 higher for average gleason. The pgstat coefficient estimate of around -0.31 showed that with average gleason, people who have a pgstat of 1 (progression), have a g2 that is 0.31 lower than people who do not have progression. The gleason_c:pgstat coefficient of around -2.09 showed that difference in slopes for different gleasons on pgstat is around -2.09.

  I then plotted the regression using ggplot, and checked assumptions of linearity, normality, and homoskedasticity graphically. I found that the normality assumption was met, the homoskedasticity assumption was not met, and the linearity assumption was met for most of the data, except a small part as seen at the right end of the graph where points curved up instead of staying in a line.

  After recomputing regression results with robust standard errors, I found that the estimates stayed almost exactly the same, but standard errors for gleason_c and gleason_c:pgstat increased, and standard error for pgstat decreased only slightly. This increase is because heteroskedasticity was accounted for with the robust standard errors. The p-values decreased for all variables, but gleason_c stayed the only significant p-value for both tests, and t-values both increased and decreased depending on the variable. All of the changes observed in this second regression with robust standard errors display that heteroskedasticity was accounted for. Lastly, I calculated R^2 to be around 0.066, which showed that my model explained 6.6% of variation in the outcome. The adjusted R^2 was around 0.029 (2.9%), which just accounted for penalty to mitigate chance association.

### 4:
```{R}
fitproject2<-lm(g2 ~ gleason_c*pgstat, data=prostate)

##Normal-theory SEs
coeftest(fitproject2)

##Robust SEs
coeftest(fitproject2, vcov=vcovHC(fitproject2))

##Bootstrapped SEs (resampling rows)
samp_distn_proj2<-replicate(5000, {
  boot_dat_proj2 <- sample_frac(prostate, replace=T)
  fitproj2_bootstrap <- lm(g2~gleason_c*pgstat, data=boot_dat_proj2)
  coef(fitproj2_bootstrap)
})

samp_distn_proj2%>%t%>%as.data.frame%>%summarize_all(sd)

```

  After rerunning the same linear regression model with interaction as before, I computed bootstrapped standard errors. The bootstrapped SE and p-value for gleason_c were higher than normal values and lower than robust values, the bootstraped SE and p-value for pgstat were lower than robust values which were lower than normal values, and the bootstrapped SE and p-value for gleason_c:pgstat were higher than normal values and lower than robust values.

### 5:
```{R}
class_diag<-function(probs,truth){
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}


logfitproject2<-glm(pgstat~grade+age, data=prostate, family="binomial")
summary(logfitproject2)
coef(logfitproject2)%>%exp%>%round(5)%>%data.frame

probsproj2<-predict(logfitproject2,type="response")
table(predict=as.numeric(probsproj2>.5),truth=prostate$pgstat)%>%addmargins

(63+26)/134
26/49
63/85
26/48


prostate$logit<-predict(logfitproject2,type="link")

prostate%>%ggplot()+geom_density(aes(logit,color=pgstat,fill=pgstat), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab("logit (log-odds)")+geom_rug(aes(logit,color=pgstat))


library(plotROC)

ROCplotproj2<-ggplot(prostate)+geom_roc(aes(d=pgstat, m=probsproj2), n.cuts = 0)

ROCplotproj2

calc_auc(ROCplotproj2)


set.seed(1234)
k=10
  
datacvproj2<-prostate[sample(nrow(prostate)),]
foldsproj2<-cut(seq(1:nrow(datacvproj2)),breaks = k, labels = F)

diags<-NULL
for(i in 1:k){
  trainproj2<-datacvproj2[foldsproj2!=i,]
  testproj2<-datacvproj2[foldsproj2==i,]
  truthcvproj2<-testproj2$pgstat
  
  fitcvproj2<-glm(pgstat~grade+age,data = trainproj2,family = "binomial")
  probscvproj2<-predict(fitcvproj2,newdata = testproj2,type="response")

diagscvproj2<-rbind(diags,class_diag(probscvproj2,truthcvproj2))
}

summarize_all(diagscvproj2,mean)

```

  I ran a logistic regression model without interaction predicting the binary categorical variable pgstat from grade and age. I then changed the log-odds scaled coefficients to odds scaled coefficients, and proceeded to interpret these new coeffeficients. The intercept of around 0.022 showed that when both grade and age are 0, the odds of a patient having observed progression is 0.022. The grade coefficient showed that when age is controlled for, for every 1 unit increase in grade, the odds of having observed progression is multiplied by around 6.70. The age coefficient showed that when grade is controlled for, for every 1 unit increase in age, the odds of having observed progression is multiplied by around 0.97. I then proceeded to make a confusion matrix in order to calculate accuracy to be around 0.664, TPR to be around 0.531, TNR to be around 0.741, and PPV to be around 0.542.

  Next, I plotted density of log-ods (logit) by pgstat, and then generated an ROC curve through which I was able to calculate an AUC of around 0.742. This AUC, which was calculated through the ROC curve, is considered fair. Lastly, I performed a 10-fold CV, and found that the average out-of-sample Accuracy was around 0.643, Sensitivity was around 0.5, and Recall was around 0.6.

### 6:
```{R}
#install.packages("glmnet")
library(glmnet)

yproj2<-as.matrix(prostate$pgstat)
xproj2<-model.matrix(pgstat~.,data=prostate)[,-1]
head(xproj2)
xproj2<-scale(xproj2)

cvlassoproj2<-cv.glmnet(xproj2,yproj2,family="binomial")
lassoproj2<-glmnet(xproj2,yproj2,family="binomial",lambda=cvlassoproj2$lambda.1se)
coef(lassoproj2)


set.seed(1234)
k=10
  
datalassoproj2<-prostate[sample(nrow(prostate)),]
foldslassoproj2<-cut(seq(1:nrow(datalassoproj2)),breaks = k, labels = F)

diags<-NULL
for(i in 1:k){
  trainlassoproj2<-datalassoproj2[foldslassoproj2!=i,]
  testlassoproj2<-datalassoproj2[foldslassoproj2==i,]
  truthlassoproj2<-testlassoproj2$pgstat
  
  fitlassoproj2<-glm(pgstat~.,data = trainlassoproj2,family = "binomial")
  probslassoproj2<-predict(fitlassoproj2,newdata = testlassoproj2,type="response")

diagslassoproj2<-rbind(diags,class_diag(probslassoproj2,truthlassoproj2))
}

diagslassoproj2%>%summarize_all(mean)

```

  I performed a LASSO regression to predict the bianry variable of pgstat, and used all of the rest of the variables as predictors. The retained variables at the end of the regression were patient, pgtime, ploidydiploid, and logit (note: not from the original dataset). This meant that these were the most predictive variables in relation to pgstat progression being observed or not. Lastly, I performed a 10-fold CV using this model, and obtained an accuracy of around 0.857. This is around 0.2 points higher than the out-of-sample accuracy from the logistic regression in #5, which was 0.643. Thus, this LASSO model increased the accuracy.

