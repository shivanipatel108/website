<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Shivani Patel" />
    <meta name="description" content="Describe your website">
    <link rel="shortcut icon" type="image/x-icon" href="/img/favicon.ico">
    <title></title>
    <meta name="generator" content="Hugo 0.69.2" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="/css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">

      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="/"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="/blog/">BLOG</a></li>
        
        <li><a href="/projects/">PROJECTS</a></li>
        
        <li><a href="/resume.pdf">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      
      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="/project2/"></a></strong>
          </h3>
        </div>
        <div class="blog-title">
          <h4>
          May 14, 2020
            &nbsp;&nbsp;
            
          </h4>
        </div>
        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              


<p>###Project 2</p>
<p>###Shivani Patel sjp2742</p>
<div id="section" class="section level3">
<h3>0:</h3>
<p>The dataset I chose for this project contains information relating to prostate cancer diagnostics and treatments for 134 separate patients. The numeric variables include pgtime, age, g2, grade, and gleason. The pgtime variable shows time to progression of cancer or last follow up in years, the age variable shows the patients’ ages in years, the g2 variable shows the percentage of cancer cells in the G2 phase of the cell cycle as found by flow cytometry, the grade variable shows the grade of the tumor in the Farrow system, and the gleason variable shows the grade of the tumor in the Gleason system. There is one categorical variable, ploidy, which indicates the ploidy status of the tumor (diploid, tetraploid, or aneuploid). Lastly, there are two binary variables, pgstat and eet. The pgstat variable shows whether progression was observed or censored, and the eet variable shows if there was early endocrine therapy or not.</p>
</div>
<div id="section-1" class="section level3">
<h3>1:</h3>
<pre class="r"><code>library(tidyverse)
library(ggplot2)
library(dplyr)

prostate &lt;-read.csv(&quot;prostate.csv&quot;)
data(&quot;prostate&quot;)
glimpse(prostate)</code></pre>
<pre><code>## Observations: 134
## Variables: 9
## $ patient &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23…
## $ pgtime &lt;dbl&gt; 6.1, 5.2, 3.2, 1.9, 4.8, 3.7, 15.9, 6.3,
2.9, 1.5, 14.5, 4.2, 1.7, 5.0, 13.2, 10.…
## $ pgstat &lt;int&gt; 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,
0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, …
## $ age &lt;int&gt; 64, 59, 62, 64, 69, 73, 64, 65, 58, 70, 67,
66, 74, 70, 57, 63, 65, 62, 72, 64, 6…
## $ eet &lt;int&gt; 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, …
## $ g2 &lt;dbl&gt; 10.26, 9.99, 3.57, 22.56, 6.14, 11.77, 27.27,
19.34, 14.82, 10.22, 15.66, 17.79, …
## $ grade &lt;int&gt; 2, 3, 2, 4, 3, 3, 3, 3, 4, 3, 2, 3, 3, 2,
2, 3, 3, 2, 3, 2, 2, 3, 3, 3, 2, 3, 2, …
## $ gleason &lt;int&gt; 4, 7, 4, 8, 7, 6, 7, 7, 8, 8, 6, 7, 8,
5, 4, 8, 7, 5, 6, 5, 5, 6, 7, 6, 5, 7, 4, …
## $ ploidy &lt;fct&gt; diploid, diploid, diploid, tetraploid,
diploid, diploid, tetraploid, tetraploid, …</code></pre>
<pre class="r"><code>manova1&lt;-manova(cbind(grade, gleason, g2)~ploidy, data=prostate)
summary(manova1)</code></pre>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## ploidy 2 0.49302 14.177 6 260 5.765e-14 ***
## Residuals 131
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>prostate%&gt;%group_by(ploidy)%&gt;%summarize(mean(grade),mean(gleason), mean(g2))</code></pre>
<pre><code>## # A tibble: 3 x 4
##   ploidy     `mean(grade)` `mean(gleason)` `mean(g2)`
##   &lt;fct&gt;              &lt;dbl&gt;           &lt;dbl&gt;      &lt;dbl&gt;
## 1 aneuploid           3               6.6        7.77
## 2 diploid             2.45            5.94       9.17
## 3 tetraploid          2.73            6.64      20.2</code></pre>
<pre class="r"><code>summary.aov(manova1)</code></pre>
<pre><code>## Response grade :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## ploidy 2 3.491 1.74570 5.3751 0.005708 **
## Residuals 131 42.546 0.32478
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response gleason :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## ploidy 2 16.371 8.1857 4.7939 0.009788 **
## Residuals 131 223.688 1.7075
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response g2 :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## ploidy 2 4146.5 2073.2 53.437 &lt; 2.2e-16 ***
## Residuals 131 5082.5 38.8
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>pairwise.t.test(prostate$grade, prostate$ploidy, p.adj=&quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  prostate$grade and prostate$ploidy 
## 
##            aneuploid diploid
## diploid    0.0382    -      
## tetraploid 0.3173    0.0048 
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(prostate$gleason, prostate$ploidy, p.adj=&quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  prostate$gleason and prostate$ploidy 
## 
##            aneuploid diploid
## diploid    0.2773    -      
## tetraploid 0.9467    0.0028 
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(prostate$g2, prostate$ploidy, p.adj=&quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  prostate$g2 and prostate$ploidy 
## 
##            aneuploid diploid
## diploid    0.63      -      
## tetraploid 3.4e-05   &lt; 2e-16
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>1-.95^13</code></pre>
<pre><code>## [1] 0.4866579</code></pre>
<pre class="r"><code>0.05/13</code></pre>
<pre><code>## [1] 0.003846154</code></pre>
<p>I first conducted a MANOVA test, which was significant with a p-value of less than 0.05. This showed that significant differences were found among the 3 types of ploidys for at least one of the numeric dependent variables of grade, gleason, and g2. Pillai trace was around 0.493, pseudo F(6, 260) was 14.177, and p was less than 0.0001.</p>
<p>I then ran univariate ANOVAs for each numeric dependent variable, which showed that all of the numeric variables were significant as well, with p values less than 0.05. For grade, F(2, 131) was around 5.375 and p was less than 0.05, for gleason, F(2, 131) was around 4.794 and p was less than 0.05, and for g2, F(2, 131) was 53.437 and p was less than 0.05.</p>
<p>I then performed post hoc t-tests, which showed that prior to adjusting the significance level, aneuploid/diploid and diploid/tetraploid significantly differed from one another in terms of grade, diploid/tetraploid significantly differed from one another in terms of gleason, and aneuploid/tetraploid and diploid/tetraploid significantly differed from one another in terms of g2.</p>
<p>After adjusting with the boneferroni adjusted significance level of 0.0038, I found that neither of the ploidys significantly differed from one another in terms of grade, diploid/tetraploid still significantly differed from one another in terms of gleason, and aneuploid/tetraploid and diploid/tetraploid still significantly differed from one another in terms of g2. I performed 13 tests in total, including 1 MANOVA, 3 ANOVAs, and 9 t tests. The probability of getting at least one type-I error if unadjusted was around 48.67%.</p>
<p>The MANOVA and ANOVA random samples/independent observations assumption was probably met, as this dataset was random and seemed to have relatively independent observations. The MANOVA multivariate normality was likely met as each group had n=25+, but the ANOVA normal distribution assumption was likely not met, as I suspect not all groups had a normal distribution. The MANOVA homogeneity assumption was likely not met as there probably wasn’t equal covariance between any 2 DVs, and the ANOVA equal variance assumption was also likely not met within each of my groups. The MANOVA linear relationships assumptions was likely not met among all of my variables, the no extreme outliers assumption was also likely not met as I spotted a few outliers in my data, and the no multicollinearity assumption was also likey violated as I suspect some of my DVs were pretty correlated.</p>
</div>
<div id="section-2" class="section level3">
<h3>2:</h3>
<pre class="r"><code>rand &lt;- data.frame(prostate$eet, prostate$age)
glimpse(rand)</code></pre>
<pre><code>## Observations: 134
## Variables: 2
## $ prostate.eet &lt;int&gt; 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1…
## $ prostate.age &lt;int&gt; 64, 59, 62, 64, 69, 73, 64, 65, 58,
70, 67, 66, 74, 70, 57, 63, 65, 62, 72, …</code></pre>
<pre class="r"><code>rand%&gt;%group_by(prostate.eet)%&gt;%
  summarize(means=mean(prostate.age))%&gt;%summarize(`mean_diff:`=diff(means))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   `mean_diff:`
##          &lt;dbl&gt;
## 1        0.642</code></pre>
<pre class="r"><code>rand_dist&lt;-vector()
for(i in 1:5000){
new&lt;-data.frame(pros.age=sample(rand$prostate.age),pros.eet=rand$prostate.eet)
rand_dist[i]&lt;-mean(new[new$pros.eet==2,]$pros.age)-
mean(new[new$pros.eet==1,]$pros.age)}

{hist(rand_dist,main=&quot;&quot;,ylab=&quot;&quot;); abline(v = 0.642,col=&quot;red&quot;)}</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-2-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>mean(rand_dist&gt;0.642)*2</code></pre>
<pre><code>## [1] 0.568</code></pre>
<p>I performed a randomization test on my two variables, age and eet. The null hypothesis was that mean age is the same for people both having early endocrine therapy (eet), and not having it. The alternative hypothesis was that mean age is different for people having eet and not having eet. I found that the true mean difference between the two means was around 0.642. I then computed a p-value on the randomization distribution, which corresponds to the probability of observing a mean difference as extreme as the original data mean difference. I obtained a p-value of 0.586. Since this number is not less than 0.05, the null hypothesis was accepted, meaning that mean age is the same for people both having eet and not having eet. In the plot to visualize the null distribution and the test statistic, I found that my test statistic layed slightly to the right of the middle of the null distribution, but only by a small amount.</p>
</div>
<div id="section-3" class="section level3">
<h3>3:</h3>
<pre class="r"><code>prostate$gleason_c &lt;- prostate$gleason - mean(prostate$gleason)
fitproject2&lt;-lm(g2 ~ gleason_c*pgstat, data=prostate)
summary(fitproject2)</code></pre>
<pre><code>##
## Call:
## lm(formula = g2 ~ gleason_c * pgstat, data = prostate)
##
## Residuals:
## Min 1Q Median 3Q Max
## -15.239 -4.562 -1.080 2.423 35.021
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 15.0023 0.8970 16.725 &lt; 2e-16 ***
## gleason_c 2.8837 0.7072 4.078 7.87e-05 ***
## pgstat -0.3139 1.5511 -0.202 0.8399
## gleason_c:pgstat -2.0864 1.1223 -1.859 0.0653 .
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 7.888 on 130 degrees of freedom
## Multiple R-squared: 0.1235, Adjusted R-squared: 0.1033
## F-statistic: 6.108 on 3 and 130 DF, p-value: 0.0006406</code></pre>
<pre class="r"><code>ggplot(prostate, aes(x = gleason_c, y = g2)) +
    geom_point(aes(color=pgstat)) + geom_smooth(method=&quot;lm&quot;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#normality assumption
residsproj2&lt;-lm(g2 ~ gleason_c*pgstat, data=prostate)$residuals
ggplot()+geom_histogram(aes(residsproj2),bins=10)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-3-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#homoskedsaticity assumption
fitvalsproj2&lt;-lm(g2 ~ gleason_c*pgstat, data=prostate)$fitted.values
ggplot()+geom_point(aes(fitvalsproj2,residsproj2))+geom_hline(yintercept=0, color=&#39;red&#39;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-3-3.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#linearity assumption
ggplot()+geom_qq(aes(sample=residsproj2))+geom_qq_line(aes(sample=residsproj2))</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-3-4.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>##install.packages(&quot;lmtest&quot;)
##install.packages(&quot;sandwich&quot;)
library(lmtest)
library(sandwich)

coeftest(fitproject2, vcov=vcovHC(fitproject2))</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 15.00228 1.15474 12.9919 &lt; 2.2e-16 ***
## gleason_c 2.88368 0.93095 3.0976 0.002391 **
## pgstat -0.31391 1.49401 -0.2101 0.833910
## gleason_c:pgstat -2.08642 1.50630 -1.3851 0.168385
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>set.seed(348)
bogusproj2&lt;-data.frame(y=prostate$g2,replicate(5,rnorm(134)))
head(bogusproj2,3)</code></pre>
<pre><code>## y X1 X2 X3 X4 X5
## 1 10.26 0.06899839 1.5095842 -0.7761833 -0.8651255
1.71682389
## 2 9.99 0.98442305 -0.7098044 -2.7660381 1.8161600
0.02157052
## 3 3.57 0.78608861 -0.5089187 -0.7423724 -0.1140753
-1.39830891</code></pre>
<pre class="r"><code>summary(lm(y~.,data=bogusproj2))</code></pre>
<pre><code>##
## Call:
## lm(formula = y ~ ., data = bogusproj2)
##
## Residuals:
## Min 1Q Median 3Q Max
## -13.227 -4.536 -1.650 2.477 40.023
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 14.51946 0.71956 20.178 &lt; 2e-16 ***
## X1 -2.00388 0.72319 -2.771 0.00642 **
## X2 0.25869 0.74189 0.349 0.72790
## X3 0.04724 0.65877 0.072 0.94295
## X4 -0.06667 0.68187 -0.098 0.92226
## X5 -0.60325 0.66172 -0.912 0.36368
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 8.208 on 128 degrees of freedom
## Multiple R-squared: 0.06556, Adjusted R-squared: 0.02906
## F-statistic: 1.796 on 5 and 128 DF, p-value: 0.1182</code></pre>
<p>I ran a linear regression model with interaction predicting g2 from gleason and pgstat, and mean-centered the numeric variable gleason. The intercept of around 15.00 showed that when both gleason_c is average and pgstat is 0 (no progression observed), g2 is 15. The gleason_c coefficient estimate of around 2.88 showed that when pgstat is 0, g2 is 2.88 higher for average gleason. The pgstat coefficient estimate of around -0.31 showed that with average gleason, people who have a pgstat of 1 (progression), have a g2 that is 0.31 lower than people who do not have progression. The gleason_c:pgstat coefficient of around -2.09 showed that difference in slopes for different gleasons on pgstat is around -2.09.</p>
<p>I then plotted the regression using ggplot, and checked assumptions of linearity, normality, and homoskedasticity graphically. I found that the normality assumption was met, the homoskedasticity assumption was not met, and the linearity assumption was met for most of the data, except a small part as seen at the right end of the graph where points curved up instead of staying in a line.</p>
<p>After recomputing regression results with robust standard errors, I found that the estimates stayed almost exactly the same, but standard errors for gleason_c and gleason_c:pgstat increased, and standard error for pgstat decreased only slightly. This increase is because heteroskedasticity was accounted for with the robust standard errors. The p-values decreased for all variables, but gleason_c stayed the only significant p-value for both tests, and t-values both increased and decreased depending on the variable. All of the changes observed in this second regression with robust standard errors display that heteroskedasticity was accounted for. Lastly, I calculated R^2 to be around 0.066, which showed that my model explained 6.6% of variation in the outcome. The adjusted R^2 was around 0.029 (2.9%), which just accounted for penalty to mitigate chance association.</p>
</div>
<div id="section-4" class="section level3">
<h3>4:</h3>
<pre class="r"><code>fitproject2&lt;-lm(g2 ~ gleason_c*pgstat, data=prostate)

##Normal-theory SEs
coeftest(fitproject2)</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 15.00228 0.89697 16.7255 &lt; 2.2e-16 ***
## gleason_c 2.88368 0.70716 4.0778 7.873e-05 ***
## pgstat -0.31391 1.55111 -0.2024 0.83994
## gleason_c:pgstat -2.08642 1.12234 -1.8590 0.06529 .
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>##Robust SEs
coeftest(fitproject2, vcov=vcovHC(fitproject2))</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 15.00228 1.15474 12.9919 &lt; 2.2e-16 ***
## gleason_c 2.88368 0.93095 3.0976 0.002391 **
## pgstat -0.31391 1.49401 -0.2101 0.833910
## gleason_c:pgstat -2.08642 1.50630 -1.3851 0.168385
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>##Bootstrapped SEs (resampling rows)
samp_distn_proj2&lt;-replicate(5000, {
  boot_dat_proj2 &lt;- sample_frac(prostate, replace=T)
  fitproj2_bootstrap &lt;- lm(g2~gleason_c*pgstat, data=boot_dat_proj2)
  coef(fitproj2_bootstrap)
})

samp_distn_proj2%&gt;%t%&gt;%as.data.frame%&gt;%summarize_all(sd)</code></pre>
<pre><code>##   (Intercept) gleason_c   pgstat gleason_c:pgstat
## 1    1.118507 0.8918377 1.451441         1.435813</code></pre>
<p>After rerunning the same linear regression model with interaction as before, I computed bootstrapped standard errors. The bootstrapped SE and p-value for gleason_c were higher than normal values and lower than robust values, the bootstraped SE and p-value for pgstat were lower than robust values which were lower than normal values, and the bootstrapped SE and p-value for gleason_c:pgstat were higher than normal values and lower than robust values.</p>
</div>
<div id="section-5" class="section level3">
<h3>5:</h3>
<pre class="r"><code>class_diag&lt;-function(probs,truth){
  
  tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord&lt;-order(probs, decreasing=TRUE)
  probs &lt;- probs[ord]; truth &lt;- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
  TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
  
  n &lt;- length(TPR)
  auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}


logfitproject2&lt;-glm(pgstat~grade+age, data=prostate, family=&quot;binomial&quot;)
summary(logfitproject2)</code></pre>
<pre><code>##
## Call:
## glm(formula = pgstat ~ grade + age, family = &quot;binomial&quot;,
data = prostate)
##
## Deviance Residuals:
## Min 1Q Median 3Q Max
## -1.3467 -1.1053 -0.5143 1.0979 2.0690
##
## Coefficients:
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -3.80983 2.43451 -1.565 0.118
## grade 1.90236 0.42166 4.512 6.43e-06 ***
## age -0.02956 0.03456 -0.855 0.392
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## (Dispersion parameter for binomial family taken to be 1)
##
## Null deviance: 175.97 on 133 degrees of freedom
## Residual deviance: 147.35 on 131 degrees of freedom
## AIC: 153.35
##
## Number of Fisher Scoring iterations: 4</code></pre>
<pre class="r"><code>coef(logfitproject2)%&gt;%exp%&gt;%round(5)%&gt;%data.frame</code></pre>
<pre><code>##                   .
## (Intercept) 0.02215
## grade       6.70170
## age         0.97087</code></pre>
<pre class="r"><code>probsproj2&lt;-predict(logfitproject2,type=&quot;response&quot;)
table(predict=as.numeric(probsproj2&gt;.5),truth=prostate$pgstat)%&gt;%addmargins</code></pre>
<pre><code>##        truth
## predict   0   1 Sum
##     0    63  23  86
##     1    22  26  48
##     Sum  85  49 134</code></pre>
<pre class="r"><code>(63+26)/134</code></pre>
<pre><code>## [1] 0.6641791</code></pre>
<pre class="r"><code>26/49</code></pre>
<pre><code>## [1] 0.5306122</code></pre>
<pre class="r"><code>63/85</code></pre>
<pre><code>## [1] 0.7411765</code></pre>
<pre class="r"><code>26/48</code></pre>
<pre><code>## [1] 0.5416667</code></pre>
<pre class="r"><code>prostate$logit&lt;-predict(logfitproject2,type=&quot;link&quot;)

prostate%&gt;%ggplot()+geom_density(aes(logit,color=pgstat,fill=pgstat), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab(&quot;logit (log-odds)&quot;)+geom_rug(aes(logit,color=pgstat))</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>library(plotROC)

ROCplotproj2&lt;-ggplot(prostate)+geom_roc(aes(d=pgstat, m=probsproj2), n.cuts = 0)

ROCplotproj2</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-5-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROCplotproj2)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.7420168</code></pre>
<pre class="r"><code>set.seed(1234)
k=10
  
datacvproj2&lt;-prostate[sample(nrow(prostate)),]
foldsproj2&lt;-cut(seq(1:nrow(datacvproj2)),breaks = k, labels = F)

diags&lt;-NULL
for(i in 1:k){
  trainproj2&lt;-datacvproj2[foldsproj2!=i,]
  testproj2&lt;-datacvproj2[foldsproj2==i,]
  truthcvproj2&lt;-testproj2$pgstat
  
  fitcvproj2&lt;-glm(pgstat~grade+age,data = trainproj2,family = &quot;binomial&quot;)
  probscvproj2&lt;-predict(fitcvproj2,newdata = testproj2,type=&quot;response&quot;)

diagscvproj2&lt;-rbind(diags,class_diag(probscvproj2,truthcvproj2))
}

summarize_all(diagscvproj2,mean)</code></pre>
<pre><code>##         acc sens      spec       ppv auc
## 1 0.7857143  0.8 0.7777778 0.6666667 0.8</code></pre>
<p>I ran a logistic regression model without interaction predicting the binary categorical variable pgstat from grade and age. I then changed the log-odds scaled coefficients to odds scaled coefficients, and proceeded to interpret these new coeffeficients. The intercept of around 0.022 showed that when both grade and age are 0, the odds of a patient having observed progression is 0.022. The grade coefficient showed that when age is controlled for, for every 1 unit increase in grade, the odds of having observed progression is multiplied by around 6.70. The age coefficient showed that when grade is controlled for, for every 1 unit increase in age, the odds of having observed progression is multiplied by around 0.97. I then proceeded to make a confusion matrix in order to calculate accuracy to be around 0.664, TPR to be around 0.531, TNR to be around 0.741, and PPV to be around 0.542.</p>
<p>Next, I plotted density of log-ods (logit) by pgstat, and then generated an ROC curve through which I was able to calculate an AUC of around 0.742. This AUC, which was calculated through the ROC curve, is considered fair. Lastly, I performed a 10-fold CV, and found that the average out-of-sample Accuracy was around 0.643, Sensitivity was around 0.5, and Recall was around 0.6.</p>
</div>
<div id="section-6" class="section level3">
<h3>6:</h3>
<pre class="r"><code>#install.packages(&quot;glmnet&quot;)
library(glmnet)

yproj2&lt;-as.matrix(prostate$pgstat)
xproj2&lt;-model.matrix(pgstat~.,data=prostate)[,-1]
head(xproj2)</code></pre>
<pre><code>## patient pgtime age eet g2 grade gleason ploidydiploid
ploidytetraploid gleason_c logit
## 1 1 6.1 64 2 10.26 2 4 1 0 -2.2985075 -1.8971008
## 2 2 5.2 59 2 9.99 3 7 1 0 0.7014925 0.1530721
## 3 3 3.2 62 2 3.57 2 4 1 0 -2.2985075 -1.8379762
## 4 4 1.9 64 2 22.56 4 8 0 1 1.7014925 1.9076217
## 5 5 4.8 69 1 6.14 3 7 1 0 0.7014925 -0.1425512
## 6 6 3.7 73 2 11.77 3 6 1 0 -0.2985075 -0.2608006</code></pre>
<pre class="r"><code>xproj2&lt;-scale(xproj2)

cvlassoproj2&lt;-cv.glmnet(xproj2,yproj2,family=&quot;binomial&quot;)
lassoproj2&lt;-glmnet(xproj2,yproj2,family=&quot;binomial&quot;,lambda=cvlassoproj2$lambda.1se)
coef(lassoproj2)</code></pre>
<pre><code>## 12 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                          s0
## (Intercept)      -0.8299081
## patient          -0.2337389
## pgtime           -1.3180148
## age               .        
## eet               .        
## g2                .        
## grade             .        
## gleason           .        
## ploidydiploid    -0.4413682
## ploidytetraploid  .        
## gleason_c         .        
## logit             0.4494145</code></pre>
<pre class="r"><code>set.seed(1234)
k=10
  
datalassoproj2&lt;-prostate[sample(nrow(prostate)),]
foldslassoproj2&lt;-cut(seq(1:nrow(datalassoproj2)),breaks = k, labels = F)

diags&lt;-NULL
for(i in 1:k){
  trainlassoproj2&lt;-datalassoproj2[foldslassoproj2!=i,]
  testlassoproj2&lt;-datalassoproj2[foldslassoproj2==i,]
  truthlassoproj2&lt;-testlassoproj2$pgstat
  
  fitlassoproj2&lt;-glm(pgstat~.,data = trainlassoproj2,family = &quot;binomial&quot;)
  probslassoproj2&lt;-predict(fitlassoproj2,newdata = testlassoproj2,type=&quot;response&quot;)

diagslassoproj2&lt;-rbind(diags,class_diag(probslassoproj2,truthlassoproj2))
}

diagslassoproj2%&gt;%summarize_all(mean)</code></pre>
<pre><code>##         acc sens spec ppv       auc
## 1 0.9285714  0.8    1   1 0.9555556</code></pre>
<p>I performed a LASSO regression to predict the bianry variable of pgstat, and used all of the rest of the variables as predictors. The retained variables at the end of the regression were patient, pgtime, ploidydiploid, and logit (note: not from the original dataset). This meant that these were the most predictive variables in relation to pgstat progression being observed or not. Lastly, I performed a 10-fold CV using this model, and obtained an accuracy of around 0.857. This is around 0.2 points higher than the out-of-sample accuracy from the logistic regression in #5, which was 0.643. Thus, this LASSO model increased the accuracy.</p>
</div>

              <hr>
              <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div>
            </div>
          </div>
          <hr>
        <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>
        </div>
      </div>
      
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with ♥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="/js/docs.min.js"></script>
<script src="/js/main.js"></script>

<script src="/js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
